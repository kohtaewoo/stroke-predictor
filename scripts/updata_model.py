import pandas as pd
import glob
import os
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import classification_report
import joblib

# --- ê²½ë¡œ ì„¤ì • ---
DATA_DIR = "data"
MODEL_DIR = "model"
MODEL_PATH = os.path.join(MODEL_DIR, "mlp_composite_model.joblib")
SCALER_PATH = os.path.join(MODEL_DIR, "scaler_composite.joblib")

# --- CSV íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸° ---
files = sorted(glob.glob(f"{DATA_DIR}/composite_feature_data_*.csv"))
if not files:
    raise FileNotFoundError("ğŸ›‘ CSV íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ì„¸ìš”.")

df_list = []
for f in files:
    temp = pd.read_csv(f)
    if "label" in temp.columns and temp["label"].notna().all():
        df_list.append(temp)

if not df_list:
    raise ValueError("âŒ ìœ íš¨í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

df = pd.concat(df_list, ignore_index=True)
print(f"ğŸ“‚ ë¶ˆëŸ¬ì˜¨ íŒŒì¼ ìˆ˜: {len(files)}ê°œ, ì´ ë°ì´í„° ìˆ˜: {len(df)}")

# --- íŠ¹ì§•ê³¼ ë¼ë²¨ ë¶„ë¦¬ ---
X = df.drop("label", axis=1)
y = df["label"].astype(int)

if y.value_counts().min() < 5:
    print("âš ï¸ ì¼ë¶€ í´ë˜ìŠ¤ ë°ì´í„° ìˆ˜ê°€ ë„ˆë¬´ ì ìŠµë‹ˆë‹¤.")

# --- ì •ê·œí™” ---
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# --- ë°ì´í„° ë¶„í•  ---
X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y, test_size=0.2, stratify=y, random_state=42
)

# --- ëª¨ë¸ í•™ìŠµ ---
model = MLPClassifier(
    hidden_layer_sizes=(64, 32),
    max_iter=1000,
    random_state=42,
    early_stopping=True,
    validation_fraction=0.1
)
model.fit(X_train, y_train)

# --- í‰ê°€ ---
y_pred = model.predict(X_test)
print("ğŸ“Š ë¶„ë¥˜ ì„±ëŠ¥:")
print(classification_report(y_test, y_pred))

# --- ëª¨ë¸ ì €ì¥ ---
os.makedirs(MODEL_DIR, exist_ok=True)
joblib.dump(model, MODEL_PATH)
joblib.dump(scaler, SCALER_PATH)
print(f"âœ… ì €ì¥ ì™„ë£Œ: {MODEL_PATH}, {SCALER_PATH}")
